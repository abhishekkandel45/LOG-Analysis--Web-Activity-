{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Loading and Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import Libraries \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load client_hostname.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/Users/abhishekkandel/Desktop/LOG Analysis/')\n",
    "print(os.getcwd())\n",
    "client_df = pd.read_csv('client_hostname.csv', sep='\\t')\n",
    "client_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load access.log\n",
    "with open('access.log', 'r') as file:\n",
    "    log_lines = file.readlines()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client_df.head())\n",
    "print(client_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Data Cleaning and Preprocessing\n",
    "\n",
    "### Parse and Clean access.log\n",
    "\n",
    "We will extract structured information from the log entries:\n",
    "- IP Address\n",
    "- Timestamp\n",
    "- Request Method\n",
    "- Requested URL\n",
    "- HTTP Version\n",
    "- Response Code\n",
    "- User Agent\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_line(line):\n",
    "    # Regular expression pattern for Apache log format\n",
    "    pattern = (\n",
    "        r'(\\S+) (\\S+) (\\S+) \\[(.*?)\\] '\n",
    "        r'\"(\\S+) (.*?) (\\S+)\" (\\d{3}) (\\d+) \"(.*?)\" \"(.*?)\" \"(.*?)\"'\n",
    "    )\n",
    "    match = re.match(pattern, line)\n",
    "    if match:\n",
    "        return {\n",
    "            'ip': match.group(1),\n",
    "            'ident': match.group(2),\n",
    "            'authuser': match.group(3),\n",
    "            'date': match.group(4),\n",
    "            'method': match.group(5),\n",
    "            'request': match.group(6),\n",
    "            'protocol': match.group(7),\n",
    "            'status': int(match.group(8)),\n",
    "            'bytes': int(match.group(9)),\n",
    "            'referrer': match.group(10),\n",
    "            'user_agent': match.group(11),\n",
    "            'unknown': match.group(12),\n",
    "        }\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Log Data\n",
    "\n",
    "We will parse the log data to extract structured information from each log entry. The extracted information will include:\n",
    "- IP Address\n",
    "- Ident\n",
    "- Authuser\n",
    "- Date\n",
    "- Method\n",
    "- Request\n",
    "- Protocol\n",
    "- Status\n",
    "- Bytes\n",
    "- Referrer\n",
    "- User Agent\n",
    "- Unknown\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_logs = []\n",
    "\n",
    "for line in log_lines:\n",
    "    parsed_line = parse_log_line(line)\n",
    "    if parsed_line:\n",
    "        parsed_logs.append(parsed_line)\n",
    "\n",
    "log_df = pd.DataFrame(parsed_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing or Malformed Entries\n",
    "log_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to Datetime\n",
    "log_df['datetime'] = log_df['date'].apply(\n",
    "    lambda x: datetime.strptime(x.split()[0], '%d/%b/%Y:%H:%M:%S')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " * Extracts product IDs and actions from a list of URLs.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_id(url):\n",
    "    match = re.search(r'/product/(\\d+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_action(url):\n",
    "    if '/product/' in url:\n",
    "        return 'view'\n",
    "    elif '/add-to-cart/' in url:\n",
    "        return 'add_to_cart'\n",
    "    elif '/purchase/' in url:\n",
    "        return 'purchase'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the functions:\n",
    "log_df['product_id'] = log_df['request'].apply(extract_product_id)\n",
    "log_df['action'] = log_df['request'].apply(extract_action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Combine Datasets\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in log_df:\", log_df.columns)\n",
    "print(\"Columns in client_df:\", client_df.columns)\n",
    "# Check the File Delimiter\n",
    "client_df = pd.read_csv('client_hostname.csv', delimiter=',')\n",
    "# Verify Column Names After Parsing\n",
    "print(client_df.columns)\n",
    "# Rename client to ip\n",
    "client_df.rename(columns={'client': 'ip'}, inplace=True)\n",
    "# Perform the Merge\n",
    "merged_df = pd.merge(log_df, client_df, on='ip', how='left')\n",
    "\n",
    "print(merged_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Handle Missing/Inconsistent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.fillna({'hostname': 'unknown'}, inplace=True)\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming a session timeout of 30 minutes:\n",
    "merged_df.sort_values(['ip', 'datetime'], inplace=True)\n",
    "\n",
    "merged_df['session_id'] = (\n",
    "    merged_df.groupby('ip')['datetime']\n",
    "    .diff().gt(pd.Timedelta(minutes=30)).cumsum()\n",
    ")\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Calculate Session Duration\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_duration = merged_df.groupby(['ip', 'session_id'])['datetime'].agg(\n",
    "    ['min', 'max']\n",
    ")\n",
    "session_duration['session_duration'] = (\n",
    "    session_duration['max'] - session_duration['min']\n",
    ").dt.total_seconds()\n",
    "\n",
    "print(session_duration.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Merge back to merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(\n",
    "    session_duration['session_duration'], on=['ip', 'session_id'], how='left'\n",
    ")\n",
    "\n",
    "print(merged_df.head())\n",
    "\n",
    "# Number of Views per Product per Session\n",
    "product_views = merged_df[merged_df['action'] == 'view'].groupby(\n",
    "    ['ip', 'session_id', 'product_id']\n",
    ").size().reset_index(name='view_count')\n",
    "\n",
    "print(product_views.head())\n",
    "\n",
    "# Merge back:\n",
    "merged_df = merged_df.merge(\n",
    "    product_views, on=['ip', 'session_id', 'product_id'], how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cart Abandonment Rate\n",
    "</h3>\n",
    "\n",
    "<p>First, identify sessions where items were added to the cart but not purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_abandoned(session_actions):\n",
    "    return 'add_to_cart' in session_actions and 'purchase' not in session_actions\n",
    "\n",
    "abandonment = (\n",
    "    merged_df.groupby(['ip', 'session_id'])['action']\n",
    "    .apply(lambda x: is_abandoned(set(x)))\n",
    "    .reset_index(name='abandoned')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abandonment.head())\n",
    "print(abandonment['abandoned'].value_counts())\n",
    "print(abandonment['abandoned'].mean())\n",
    "print(abandonment['abandoned'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge back:\n",
    "merged_df = merged_df.merge(\n",
    "    abandonment, on=['ip', 'session_id'], how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we'll use Label Encoding here\n",
    "le_action = LabelEncoder()\n",
    "merged_df['action_encoded'] = le_action.fit_transform(merged_df['action'])\n",
    "\n",
    "le_product = LabelEncoder()\n",
    "merged_df['product_id_encoded'] = merged_df['product_id'].astype(str)\n",
    "merged_df['product_id_encoded'] = le_product.fit_transform(\n",
    "    merged_df['product_id_encoded']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.head())\n",
    "\n",
    "# Session Level Aggregations\n",
    "session_features = merged_df.groupby(['ip', 'session_id']).agg({\n",
    "    'session_duration': 'first',\n",
    "    'view_count': 'sum',\n",
    "    'abandoned': 'first',\n",
    "    'action_encoded': list,\n",
    "    'product_id_encoded': list,\n",
    "})\n",
    "session_features.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> User Behavior Trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_over_time = merged_df.groupby(\n",
    "    merged_df['datetime'].dt.date\n",
    ")['action'].value_counts().unstack().fillna(0)\n",
    "\n",
    "actions_over_time.plot(kind='line', figsize=(12, 6))\n",
    "plt.title('User Actions Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Action')\n",
    "plt.show() \n",
    "\n",
    "print(actions_over_time)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Viewed Products\n",
    "most_viewed_products = merged_df[merged_df['action'] == 'view']['product_id'].value_counts().head(10)\n",
    "\n",
    "sns.barplot(x=most_viewed_products.values, y=most_viewed_products.index)\n",
    "plt.title('Top 10 Most Viewed Products')\n",
    "plt.xlabel('View Count')\n",
    "plt.ylabel('Product ID')\n",
    "plt.show()\n",
    "\n",
    "print(most_viewed_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abandomnent Trends\n",
    "\n",
    "abandonment_rate = abandonment['abandoned'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.pie(\n",
    "    abandonment_rate,\n",
    "    labels=abandonment_rate.index.map({False: 'Not Abandoned', True: 'Abandoned'}),\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=140\n",
    ")\n",
    "plt.title('Cart Abandonment Rate')\n",
    "plt.show()\n",
    "\n",
    "print(abandonment_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Heatmap of Feature Correlations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged_df[['session_duration', 'view_count', 'abandoned']].corr()\n",
    "\n",
    "sns.heatmap(corr, annot=True)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model  Building \n",
    "\n",
    "<b> Define Target Variable</b>\n",
    "\n",
    "We will predict whether a session will lead to a purchase (purchase action in the session).\n",
    "\n",
    "Create target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'purchase' is included in the labels\n",
    "le_action.fit(merged_df['action'].tolist() + ['purchase'])\n",
    "\n",
    "session_features['purchase'] = session_features['action_encoded'].apply(\n",
    "    lambda x: 1 if le_action.transform(['purchase'])[0] in x else 0\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "\n",
    "X = session_features[['session_duration', 'view_count', 'abandoned']]\n",
    "y = session_features['purchase']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "# Printing woth label \n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "print(X_test.head())\n",
    "print(y_test.head())\n",
    "\n",
    "# Graphical Representation\n",
    "sns.pairplot(session_features, hue='purchase')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_logreg))\n",
    "print('Precision:', precision_score(y_test, y_pred_logreg))\n",
    "print('Recall:', recall_score(y_test, y_pred_logreg))\n",
    "print('F1 Score:', f1_score(y_test, y_pred_logreg))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_logreg))\n",
    "\n",
    "\n",
    "# Graphical Representation\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_logreg)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# SNS Graphical Representation\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_logreg), annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print('Random Forest:')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('Precision:', precision_score(y_test, y_pred_rf))\n",
    "print('Recall:', recall_score(y_test, y_pred_rf))\n",
    "print('F1 Score:', f1_score(y_test, y_pred_rf))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Graphical Representation\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "feature_importance.nlargest(10).plot(kind='barh')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "print(feature_importance)\n",
    "\n",
    "# SNS Pairplot\n",
    "\n",
    "sns.pairplot(session_features, hue='purchase')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "print('Gradient Boosting:')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_gb))\n",
    "print('Precision:', precision_score(y_test, y_pred_gb))\n",
    "print('Recall:', recall_score(y_test, y_pred_gb))\n",
    "print('F1 Score:', f1_score(y_test, y_pred_gb))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_gb))\n",
    "\n",
    "# Graphical Representation\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_gb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.Series(gb.feature_importances_, index=X_train.columns)\n",
    "feature_importance.nlargest(10).plot(kind='barh')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "print(feature_importance)\n",
    "\n",
    "\n",
    "# SNS Pairplot\n",
    "sns.pairplot(session_features, hue='purchase')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluatoion \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Metrics\n",
    "acc_logreg, prec_logreg, rec_logreg, f1_logreg = calculate_metrics(y_test, y_pred_logreg)\n",
    "# Random Forest Metrics\n",
    "acc_rf, prec_rf, rec_rf, f1_rf = calculate_metrics(y_test, y_pred_rf)\n",
    "# Gradient Boosting Metrics\n",
    "acc_gb, prec_gb, rec_gb, f1_gb = calculate_metrics(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Accuracy': [acc_logreg, acc_rf, acc_gb],\n",
    "    'Precision': [prec_logreg, prec_rf, prec_gb],\n",
    "    'Recall': [rec_logreg, rec_rf, rec_gb],\n",
    "    'F1 Score': [f1_logreg, f1_rf, f1_gb],\n",
    "})\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "models = [logreg, rf, gb]\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'Gradient Boosting']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model, X_test, y_test, display_labels=['No Purchase', 'Purchase'], cmap=plt.cm.Blues\n",
    "    )\n",
    "    disp.ax_.set_title(f'Confusion Matrix: {name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    auc_score = roc_auc_score(y_test, y_score)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Random chance\n",
    "plt.title('ROC Curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behaviour Analysis \n",
    "\n",
    "User Behavior Patterns\n",
    "\n",
    "Identify patterns such as:<br>\n",
    "Frequent Viewers: Users with high view counts but no purchasesFrequent <br>\n",
    "Buyers: Users with frequent purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_features['user_type'] = session_features.apply(\n",
    "    lambda x: 'Frequent Buyer' if x['purchase'] == 1 else 'Frequent Viewer', axis=1\n",
    ")\n",
    "\n",
    "sns.pairplot(session_features, hue='user_type')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High Abandonment Products or Sessions\n",
    "high_abandonment_sessions = session_features[session_features['abandoned'] == True]\n",
    "\n",
    "print(high_abandonment_sessions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance from Random Forest\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feature_importances.sort_values().plot(kind='barh')\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "print(feature_importances)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
